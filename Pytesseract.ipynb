{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c4234c",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "027493cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/mustafa/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /home/mustafa/.local/lib/python3.8/site-packages (from opencv-python) (1.22.3)\n",
      "Requirement already satisfied: tensorflow in /home/mustafa/.local/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.8)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mustafa/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mustafa/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/mustafa/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mustafa/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/mustafa/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/mustafa/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mustafa/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pytesseract in /home/mustafa/.local/lib/python3.8/site-packages (0.3.9)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/mustafa/.local/lib/python3.8/site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from pytesseract) (9.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from packaging>=21.3->pytesseract) (3.0.8)\n",
      "Requirement already satisfied: spacy in /home/mustafa/.local/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (8.0.16)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.22.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/mustafa/.local/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mustafa/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mustafa/.local/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "!pip install pytesseract\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881b845",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4426083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "try:\n",
    " from PIL import Image\n",
    "except ImportError:\n",
    " import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e86a4",
   "metadata": {},
   "source": [
    "# Downloading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cc6fcf7f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-18 12:30:37.290270: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mustafa/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-18 12:30:37.290299: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Requirement already satisfied: en-core-web-sm==3.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl#egg=en_core_web_sm==3.3.0 in /home/mustafa/.local/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/mustafa/.local/lib/python3.8/site-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.22.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (45.2.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.22.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.16)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/mustafa/.local/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mustafa/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/mustafa/.local/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mustafa/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/mustafa/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mustafa/.local/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19b21d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mustafa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mustafa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/mustafa/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/mustafa/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d7abb",
   "metadata": {},
   "source": [
    "# Pre Processing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d0910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZoomImage(img, zoom_factor=2):\n",
    "    return cv2.resize(img, None, fx= zoom_factor, fy= zoom_factor, interpolation= cv2.INTER_LINEAR)\n",
    "\n",
    "def GrayScaleImage(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = 255*(gray < 128).astype(np.uint8) \n",
    "    return gray\n",
    "\n",
    "def remove_noise(img):\n",
    "    return cv2.medianBlur(img,5)\n",
    "\n",
    "def InvertImage(img):\n",
    "    return cv2.bitwise_not(img)\n",
    "\n",
    "def CropImage(img):\n",
    "    # Find all non-zero points (text)\n",
    "    coords = cv2.findNonZero(img) \n",
    "    # Find minimum spanning bounding box\n",
    "    x, y, w, h = cv2.boundingRect(coords) \n",
    "    # Crop the image - note we do this on the original image\n",
    "    img = img[y:y+h, x:x+w] \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0583535",
   "metadata": {},
   "source": [
    "# Creating Bounding Box In Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37bd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBoundingBox(img):\n",
    "    h, w, c = img.shape\n",
    "    boxes = pytesseract.image_to_boxes(img) \n",
    "    for b in boxes.splitlines():\n",
    "        b = b.split(' ')\n",
    "        img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ff256",
   "metadata": {},
   "source": [
    "# Extracting Text From Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958fe4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractText(img) : \n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    text = pytesseract.image_to_string(img, config=custom_config)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870b6f3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Remove Extra White Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862cada",
   "metadata": {},
   "source": [
    "Removing Extra Spaces for Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d5393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# # valid_characters = re.compile(\"[A-Za-z0-9]+\")\n",
    "# words = word_tokenize(text)\n",
    "# for i in words:\n",
    "# #     if '@' in i:\n",
    "#     print(i)\n",
    "# for i in range(len(text)):\n",
    "#     if text[i] == '@':\n",
    "#         while (not valid_characters.fullmatch(text[i])):\n",
    "#             i = i - 1\n",
    "#             if (text[i] == ' '):\n",
    "                \n",
    "#         print(text[i])\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2a5c6",
   "metadata": {},
   "source": [
    "# Extracting Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1267d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 19:48:09.917939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mustafa/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-19 19:48:09.917969: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "ignore_text1 = \"CURRICULUM\"\n",
    "ignore_text2 = \"VITAE\"\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(content):\n",
    "    nlp_text = nlp(content)\n",
    "    \n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', [pattern])\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        if not(ignore_text1.lower() in span.text.lower() or ignore_text2.lower() in span.text.lower()) :\n",
    "            return span.text\n",
    "        \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62d346",
   "metadata": {},
   "source": [
    "# Extracting Phone Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7116e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
    "def extract_phone_number(resume_text):\n",
    "    phone = re.findall(PHONE_REG, resume_text)\n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    " \n",
    "        if resume_text.find(number) >= 0 and len(number) < 16:\n",
    "            return number\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23674a75",
   "metadata": {},
   "source": [
    "# Extracting Email ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc5c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    "\n",
    "def extract_emails(resume_text):\n",
    "    return re.findall(EMAIL_REG, resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296cedd",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08f72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mubasheer ahmed', '+919182834870', ['mubasheerkhan@gmail.com']]\n",
      "[]\n",
      "['jumeirah beach', None, ['gppraveen19@gmail.com']]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "\n",
    "with open('output_top_10.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for i in range(10):\n",
    "        IMG_PATH = 'SampleResumes/' + str(i+1)\n",
    "        text = \"\"\n",
    "        img_list = []\n",
    "        for filename in glob.glob(IMG_PATH + '/*.jpeg'): \n",
    "            \n",
    "            # Img Pre Processing\n",
    "            \n",
    "            img = cv2.imread(filename)\n",
    "\n",
    "            img = ZoomImage(img , 3)\n",
    "            img = GrayScaleImage(img)\n",
    "            img = CropImage(img)\n",
    "            img = InvertImage(img)\n",
    "\n",
    "            cv2.imwrite(IMG_PATH + '/0.png', img)\n",
    "            img = cv2.imread(IMG_PATH + '/0.png')\n",
    "\n",
    "            boundedImg = CreateBoundingBox(img)\n",
    "            cv2.imwrite(IMG_PATH + '/a.png', boundedImg)\n",
    "            \n",
    "            img = cv2.imread(IMG_PATH + '/0.png')\n",
    "\n",
    "            # NLP Part\n",
    "\n",
    "            text = ExtractText(img)\n",
    "            text = text + \"\\n\"\n",
    "\n",
    "        personName = extract_name(text.lower())\n",
    "        contactNum = extract_phone_number(text.lower())\n",
    "        emailID = extract_emails(text.lower())\n",
    "        \n",
    "        row = []\n",
    "        row.append(personName)\n",
    "        row.append(contactNum)\n",
    "        row.append(emailID)\n",
    "        print(row)\n",
    "        \n",
    "        writer.writerow(row)\n",
    "        print(img_list)\n",
    "#         break\n",
    "    f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6e9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
