{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3c4234c",
      "metadata": {
        "id": "b3c4234c"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027493cc",
      "metadata": {
        "collapsed": true,
        "id": "027493cc"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow\n",
        "!pip install spacy\n",
        "!sudo apt update"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!apt-get install poppler-utils\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UIK0r2jMNotK",
        "outputId": "380f82bd-d860-4f9a-cd78-731e6df1d85c"
      },
      "id": "UIK0r2jMNotK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n",
            "Collecting Pillow>=8.0.0\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
            "Installing collected packages: Pillow, pytesseract\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.2.0 pytesseract-0.3.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 154 kB of archives.\n",
            "After this operation, 613 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.12 [154 kB]\n",
            "Fetched 154 kB in 1s (261 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Setting up poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,408 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155681 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 1s (2,756 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 155728 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Restart Runtime After Installation"
      ],
      "metadata": {
        "id": "-iCqt_hgBo5D"
      },
      "id": "-iCqt_hgBo5D"
    },
    {
      "cell_type": "markdown",
      "id": "1881b845",
      "metadata": {
        "id": "1881b845"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4426083",
      "metadata": {
        "id": "c4426083"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "050e86a4",
      "metadata": {
        "id": "050e86a4"
      },
      "source": [
        "# Downloading Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc6fcf7f",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc6fcf7f",
        "outputId": "9453c35a-c78f-4a8f-cade-99411f7ca049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19b21d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d19b21d1",
        "outputId": "b0aec920-94c6-4d24-acb0-49d21d66272b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive"
      ],
      "metadata": {
        "id": "_bkGRDFGB4Sa"
      },
      "id": "_bkGRDFGB4Sa"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CIYUFICaPQ-",
        "outputId": "0f231d34-e262-4df0-91d9-c5e9630c9f81"
      },
      "id": "-CIYUFICaPQ-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788d7abb",
      "metadata": {
        "id": "788d7abb"
      },
      "source": [
        "# Pre Processing Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d0910b",
      "metadata": {
        "id": "27d0910b"
      },
      "outputs": [],
      "source": [
        "def ZoomImage(img, zoom_factor=2):\n",
        "    return cv2.resize(img, None, fx= zoom_factor, fy= zoom_factor, interpolation= cv2.INTER_LINEAR)\n",
        "\n",
        "def GrayScaleImage(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = 255*(gray < 128).astype(np.uint8) \n",
        "    return gray\n",
        "\n",
        "def InvertImage(img):\n",
        "    return cv2.bitwise_not(img)\n",
        "\n",
        "def CropImage(img):\n",
        "    # Find all non-zero points (text)\n",
        "    coords = cv2.findNonZero(img) \n",
        "    # Find minimum spanning bounding box\n",
        "    x, y, w, h = cv2.boundingRect(coords) \n",
        "    # Crop the image - note we do this on the original image\n",
        "    img = img[y:y+h, x:x+w] \n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0583535",
      "metadata": {
        "id": "b0583535"
      },
      "source": [
        "# Creating Bounding Box In Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37bd914",
      "metadata": {
        "id": "c37bd914"
      },
      "outputs": [],
      "source": [
        "def CreateBoundingBox(img):\n",
        "    h, w, c = img.shape\n",
        "    boxes = pytesseract.image_to_boxes(img) \n",
        "    for b in boxes.splitlines():\n",
        "        b = b.split(' ')\n",
        "        img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9ff256",
      "metadata": {
        "id": "ff9ff256"
      },
      "source": [
        "# Extracting Text From Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958fe4fd",
      "metadata": {
        "id": "958fe4fd"
      },
      "outputs": [],
      "source": [
        "def ExtractText(img) : \n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    text = pytesseract.image_to_string(img, config=custom_config)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb2a5c6",
      "metadata": {
        "id": "ffb2a5c6"
      },
      "source": [
        "# Extracting Name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre Processing For Name"
      ],
      "metadata": {
        "id": "8qqPGeKMxKgO"
      },
      "id": "8qqPGeKMxKgO"
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "  newSentence = \"\"\n",
        "  for word in text:\n",
        "      if (word in punctuations):\n",
        "          newSentence = newSentence + \" \"\n",
        "      else: \n",
        "          newSentence = newSentence + word\n",
        "\n",
        "  return newSentence\n",
        "\n",
        "def remove_white_spaces(text):\n",
        "  token_words = word_tokenize(text)\n",
        "  new_sentence = []\n",
        "  for word in token_words:\n",
        "    new_sentence.append(word) \n",
        "    new_sentence.append(\" \") \n",
        "  return \"\".join(new_sentence)\n",
        "\n",
        "def removing_extra(text):\n",
        "  new_sentence = \"\"\n",
        "  result = \"\"\n",
        "  token_sentence = sent_tokenize(text)\n",
        "  if \"applying for\" in token_sentence[0].lower() or \"applied for\" in token_sentence[0].lower():\n",
        "    sentences = token_sentence[0].split(\"\\n\")\n",
        "    for sent in sentences:\n",
        "      if \"applying for\" in sent.lower() or \"applied for\" in sent.lower():\n",
        "        continue\n",
        "      else:\n",
        "        new_sentence = new_sentence + sent + \"\\n\"\n",
        "\n",
        "    i = 0\n",
        "    for sentence in token_sentence:\n",
        "      if i == 0:\n",
        "        result = result + new_sentence + \"\\n\"\n",
        "      else:\n",
        "        result = result + sentence  + \"\\n\"\n",
        "      i += 1\n",
        "    return result \n",
        "  else:\n",
        "    return text"
      ],
      "metadata": {
        "id": "rgfz0pIaop7A"
      },
      "id": "rgfz0pIaop7A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1267d1",
      "metadata": {
        "id": "bc1267d1"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "ignore_text1 = \"CURRICULUM\"\n",
        "ignore_text2 = \"VITAE\"\n",
        "ignore_text3 = \"VITA\"\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "def extract_name(content):\n",
        "    # new_content = text_preprocessing(content)\n",
        "    new_content = removing_extra(content)\n",
        "    # print(new_content)\n",
        "    nlp_text = nlp(new_content)\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>/?@#$%^&*_~'''\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', [pattern])\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        # print(span.text)\n",
        "        if not(ignore_text1.lower() in span.text.lower() or ignore_text2.lower() in span.text.lower() or ignore_text3.lower() in span.text.lower()):\n",
        "          token_words = word_tokenize(span.text)\n",
        "          flag = 0\n",
        "          for word in token_words:\n",
        "            if word in punctuations:\n",
        "              flag = 1 \n",
        "              break\n",
        "          if flag == 0:\n",
        "            return span.text\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a62d346",
      "metadata": {
        "id": "3a62d346"
      },
      "source": [
        "# Extracting Phone Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7116e5a1",
      "metadata": {
        "id": "7116e5a1"
      },
      "outputs": [],
      "source": [
        "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG, resume_text)\n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        " \n",
        "        if resume_text.find(number) >= 0 and len(number) < 16:\n",
        "            return number\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Phone Number"
      ],
      "metadata": {
        "id": "laQCMZk9CPZ8"
      },
      "id": "laQCMZk9CPZ8"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q4VhslPzCOFz"
      },
      "id": "q4VhslPzCOFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "23674a75",
      "metadata": {
        "id": "23674a75"
      },
      "source": [
        "# Extracting Email ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc5c1d8",
      "metadata": {
        "id": "9dc5c1d8"
      },
      "outputs": [],
      "source": [
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "\n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Email ID"
      ],
      "metadata": {
        "id": "oD35jyRqCKTi"
      },
      "id": "oD35jyRqCKTi"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_emails(emailID):\n",
        "\n",
        "  # Identifying the string slicing for gmail\n",
        "  if type(emailID) == list:\n",
        "    emailNum = 0\n",
        "    for eml in emailID:\n",
        "        for i in range(len(eml)):\n",
        "          if eml[i] == '@':\n",
        "            index1 = i\n",
        "            break\n",
        "        for j in range(index1 , len(eml)):\n",
        "          if eml[j] == '.':\n",
        "            index2 = j\n",
        "            break\n",
        "        if eml[index1 + 1:index2] == 'qmail' or eml[index1 + 1:index2] == 'gqmail':\n",
        "          part1 = eml[0:index1 + 1]\n",
        "          part2 = eml[index1 + 1 : index2]\n",
        "          part3 = eml[index2:len(eml)]\n",
        "          eml = part1 + 'gmail' + part3\n",
        "        emailID[emailNum] = eml\n",
        "        emailNum =  emailNum + 1\n",
        "  else:\n",
        "    for i in range(len(emailID)):\n",
        "      if emailID[i] == '@':\n",
        "        index1 = i\n",
        "        break\n",
        "    for j in range(index1 , len(emailID)):\n",
        "      if emailID[j] == '.':\n",
        "        index2 = j\n",
        "        break\n",
        "    part1 = emailID[0:index1 + 1]\n",
        "    part2 = emailID[index1 + 1 : index2]\n",
        "    part3 = emailID[index2:len(emailID)]\n",
        "    emailID = part1 + 'gmail' + part3"
      ],
      "metadata": {
        "id": "XAQDY7usCJ7y"
      },
      "id": "XAQDY7usCJ7y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d296cedd",
      "metadata": {
        "id": "d296cedd"
      },
      "source": [
        "# Main Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f08f72b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f08f72b",
        "outputId": "55c44323-6fb7-4059-e3ff-87dfd21a4d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Krishanu Sen', '+91-9647496690', ['krishanusen.krishanu@gmail.com']]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import glob\n",
        "\n",
        "with open('output.csv', 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    for i in range(30):\n",
        "        IMG_PATH = '/content/drive/MyDrive/sampleresumes/' + str(i+110)\n",
        "        text = \"\"\n",
        "        \n",
        "        # Img Pre Processing\n",
        "              \n",
        "        img = cv2.imread(IMG_PATH + '/page0.jpeg' )\n",
        "\n",
        "        img = ZoomImage(img , 3)\n",
        "        img = GrayScaleImage(img)\n",
        "        img = CropImage(img)\n",
        "        img = InvertImage(img)\n",
        "\n",
        "        cv2.imwrite(IMG_PATH + '/0.png', img)\n",
        "        img = cv2.imread(IMG_PATH + '/0.png')\n",
        "\n",
        "        boundedImg = CreateBoundingBox(img)\n",
        "        cv2.imwrite(IMG_PATH + '/a.png', boundedImg)\n",
        "        \n",
        "        img = cv2.imread(IMG_PATH + '/0.png')\n",
        "\n",
        "        # NLP Part\n",
        "\n",
        "        text = ExtractText(img)\n",
        "        # print(text)      \n",
        "        personName = extract_name(text.title())\n",
        "        contactNum = extract_phone_number(text.lower())\n",
        "        emailID = extract_emails(text.lower())\n",
        "        process_emails(emailID)\n",
        "\n",
        "        row = []\n",
        "        row.append(personName)\n",
        "        row.append(contactNum)\n",
        "        row.append(emailID)\n",
        "        print(row)\n",
        "        \n",
        "        writer.writerow(row)\n",
        "        break\n",
        "    f.close()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hf1bzBqHerRy"
      },
      "id": "Hf1bzBqHerRy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Pytesseract.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}